<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Chaos Feild</title>
    <link rel="stylesheet" href="style.css"> 
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  </head>
  <body>
    <img id='test' width='128' height='128' src='https://raw.githubusercontent.com/Komponent1/chaosfield/master/app/chaos.png' crossorigin="anonymous"/>
    <button id='start' disabled='disabled'>Start</button>
    <button id='stop' disabled='disabled'>Stop</button>
    <canvas id="canvas1" width="128" height="128"></canvas>
    <canvas id="canvas2" width="128" height="128"></canvas>
    <video id='video' autoplay ></video>
    <div id="list">

    </div>
  </body>
  <script type='text/javascript'>
    const screen = document.getElementById('video');
    const start = document.getElementById('start');
    const stop = document.getElementById('stop');
    const img = document.getElementById('test');
    const list = document.getElementById('list');
    
    let target = null;
    let model = null;
    let id = null;

    async function setModel() {
      model = await tf.loadGraphModel("https://tfhub.dev/google/tfjs-model/imagenet/mobilenet_v2_075_128/feature_vector/2/default/1", { fromTFHub: true })
      const ctx = document.getElementById('canvas1').getContext('2d');
      ctx.drawImage(img, 0, 0);
      const grayimg = grayScale(ctx.getImageData(0,0, 128, 128));
      ctx.putImageData(grayimg, 0, 0);
      target = getFeature(grayimg);

      start.disabled = false;
      stop.disabled = false;
    };
    setModel();
    function getFeature(input) {
      let tfimg = tf.cast(tf.browser.fromPixels(input), 'float32');
      tfimg = tfimg.reshape([1, ...tfimg.shape]); 
      const featrue = model.execute(tfimg);

      return featrue;
    }
    function getSimilarty(input) {
      const dot = tf.dot(target, tf.transpose(input));
      const a = tf.sqrt(tf.dot(target, tf.transpose(target)));
      const b = tf.sqrt(tf.dot(input, tf.transpose(input)));
      const sim = dot.div(a.mul(b));

      return sim.dataSync();
    }
    
    function grayScale(imgData) {
      for (i = 0; i < imgData.data.length; i += 4) {
        let count = imgData.data[i] + imgData.data[i + 1] + imgData.data[i + 2];
        let colour = 0;
        if (count > 383) colour = 255;

        imgData.data[i] = colour;
        imgData.data[i + 1] = colour;
        imgData.data[i + 2] = colour;
        imgData.data[i + 3] = 255;
      }

      return imgData;
    }

    function getImgFromVideo(position) {
      const canvas1 = document.createElement('canvas');
      const ctx1 = canvas1.getContext('2d');
      canvas1.width = screen.videoWidth;
      canvas1.height = screen.videoHeight;
      ctx1.drawImage(screen, 0, 0, screen.videoWidth, screen.videoHeight);
      

      let capture = ctx1.getImageData(...position);
      const canvas2 = document.getElementById('canvas2');
      const ctx2 = canvas2.getContext('2d');
      canvas2.width = 128;
      canvas2.height = 128;
      ctx2.putImageData(capture, 0, 0);
      ctx2.fillStyle = '#FFFFFF';
      ctx2.fillRect(0, 0, 128, 35);
      ctx2.fillRect(0, 95, 128, 128);

      capture = ctx2.getImageData(0, 0, 128, 128);
      capture = grayScale(capture);
      ctx2.putImageData(capture, 0, 0);

      return capture;
    }

    function check() {
      const img = getImgFromVideo([958, 234, 128, 128]);
      const feature = getFeature(img);
      const sim = getSimilarty(feature);

      if (sim[0] > 0.8) {
        const c = document.createElement('canvas');
        const ctx = c.getContext('2d');
        ctx.putImageData(img, 0, 0);
        ctx.font = '20px serif';
        ctx.fillStyle = 'black';
        console.log(sim[0] + '')
        ctx.fillText(sim[0] + '', 20, 20);
        list.appendChild(c);
      }
    }
    async function startCapture() {
      let captureStream = null;

      const option = {
        audio: false,
        displaySurface: 'application',
        video: { 
          cursor: 'always',
        }
      };

      try {
        captureStream = await navigator.mediaDevices.getDisplayMedia(option);
        screen.srcObject = captureStream;

        id = setInterval(check, 1000);
      } catch (err) {
        console.log(err);
      }

      return captureStream;
    }
    function stopCapture() {
      const tracks = screen.srcObject.getTracks();
      tracks.forEach(track => track.stop());
      screen.srcObject = null;

      clearInterval(id);
    }
    start.addEventListener('click', startCapture);
    stop.addEventListener('click', stopCapture);

  </script>
</html>